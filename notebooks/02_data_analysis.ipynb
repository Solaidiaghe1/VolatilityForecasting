{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f8c71d",
   "metadata": {},
   "source": [
    "# Data Loading and Analysis\n",
    "\n",
    "This notebook provides a comprehensive guide to loading, cleaning, and analyzing financial data using the Volatility Forecasting toolkit.\n",
    "\n",
    "## Topics Covered\n",
    "1. Loading data from multiple sources\n",
    "2. Data cleaning and validation\n",
    "3. Handling missing values and outliers\n",
    "4. Returns calculation and analysis\n",
    "5. Statistical tests and diagnostics\n",
    "\n",
    "Let's dive in! üìä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579f726",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e83d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_loader import DataLoader, fetch_prices, load_prices\n",
    "from returns import ReturnsCalculator, compute_log_returns, compute_simple_returns\n",
    "from utils import setup_plot_style, validate_dataframe\n",
    "\n",
    "setup_plot_style()\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38d8ce",
   "metadata": {},
   "source": [
    "## 1. Loading Data from Yahoo Finance\n",
    "\n",
    "The easiest way to get started is loading data from Yahoo Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8803d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for multiple tickers\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "period = '1y'\n",
    "\n",
    "print(f\"üì• Loading data for {', '.join(tickers)}...\")\n",
    "print(f\"üìÖ Period: {period}\\n\")\n",
    "\n",
    "loader = DataLoader()\n",
    "prices = loader.load_from_yfinance(\n",
    "    tickers=tickers,\n",
    "    period=period,\n",
    "    interval='1d'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded!\")\n",
    "print(f\"üìä Shape: {prices.shape}\")\n",
    "print(f\"üìÖ Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the data\n",
    "print(\"üìä First few rows:\")\n",
    "print(prices.head())\n",
    "\n",
    "print(\"\\nüìä Last few rows:\")\n",
    "print(prices.tail())\n",
    "\n",
    "print(\"\\nüìä Data info:\")\n",
    "print(prices.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13140b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all price series\n",
    "fig, axes = plt.subplots(len(tickers), 1, figsize=(14, 4*len(tickers)))\n",
    "\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01']\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    ax = axes[idx] if len(tickers) > 1 else axes\n",
    "    ax.plot(prices.index, prices[ticker], linewidth=2, color=colors[idx], label=ticker)\n",
    "    ax.set_title(f'{ticker} Price History', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=11)\n",
    "    ax.set_ylabel('Price ($)', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bacd65",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "Real-world data often contains missing values, outliers, and other issues. Let's clean it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581425cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Checking for missing values...\\n\")\n",
    "\n",
    "missing_count = prices.isna().sum()\n",
    "print(\"Missing values per ticker:\")\n",
    "print(missing_count)\n",
    "\n",
    "missing_pct = (prices.isna().sum() / len(prices)) * 100\n",
    "print(\"\\nMissing percentage:\")\n",
    "print(missing_pct.round(2))\n",
    "\n",
    "# Check for zeros\n",
    "zero_count = (prices == 0).sum()\n",
    "print(\"\\nZero values per ticker:\")\n",
    "print(zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "print(\"üßπ Cleaning data...\\n\")\n",
    "\n",
    "clean_prices = loader.clean_data(\n",
    "    handle_missing='ffill',  # Forward fill missing values\n",
    "    handle_zeros='ffill',    # Forward fill zeros\n",
    "    drop_na_threshold=0.5    # Drop columns with >50% missing\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Data cleaned!\")\n",
    "print(f\"üìä Final shape: {clean_prices.shape}\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\n‚úì Missing values remaining: {clean_prices.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c89d9",
   "metadata": {},
   "source": [
    "## 3. Data Validation\n",
    "\n",
    "Always validate your data before analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38d74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive validation\n",
    "print(\"‚úÖ Validating data...\\n\")\n",
    "\n",
    "validation = loader.validate_data()\n",
    "\n",
    "print(f\"Data valid: {'‚úÖ' if validation['is_valid'] else '‚ùå'}\")\n",
    "\n",
    "if validation['issues']:\n",
    "    print(\"\\n‚ö†Ô∏è  Issues found:\")\n",
    "    for issue in validation['issues']:\n",
    "        print(f\"   - {issue}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No issues found!\")\n",
    "\n",
    "print(f\"\\nüìä Data Statistics:\")\n",
    "stats = validation['stats']\n",
    "print(f\"   Rows: {stats['n_rows']}\")\n",
    "print(f\"   Columns: {stats['n_cols']}\")\n",
    "print(f\"   Tickers: {', '.join(stats['tickers'])}\")\n",
    "print(f\"   Date range: {stats['date_range'][0].date()} to {stats['date_range'][1].date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for gaps in data\n",
    "print(\"üìÖ Checking for date gaps...\\n\")\n",
    "\n",
    "date_diffs = pd.Series(prices.index).diff()\n",
    "large_gaps = date_diffs[date_diffs > pd.Timedelta(days=7)]\n",
    "\n",
    "if len(large_gaps) > 0:\n",
    "    print(f\"‚ö†Ô∏è  Found {len(large_gaps)} gaps > 7 days:\")\n",
    "    for idx, gap in large_gaps.items():\n",
    "        if idx > 0:\n",
    "            print(f\"   {prices.index[idx-1].date()} -> {prices.index[idx].date()} ({gap.days} days)\")\n",
    "else:\n",
    "    print(\"‚úÖ No large gaps found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac20423b",
   "metadata": {},
   "source": [
    "## 4. Returns Calculation\n",
    "\n",
    "Calculate returns using different methods and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßÆ Calculating returns...\\n\")\n",
    "\n",
    "# Method 1: Log returns (preferred for volatility)\n",
    "log_returns = compute_log_returns(clean_prices)\n",
    "print(f\"‚úÖ Log returns calculated: {log_returns.shape}\")\n",
    "\n",
    "# Method 2: Simple returns\n",
    "simple_returns = compute_simple_returns(clean_prices)\n",
    "print(f\"‚úÖ Simple returns calculated: {simple_returns.shape}\")\n",
    "\n",
    "print(f\"\\nüìä Returns summary (log returns):\")\n",
    "print(log_returns.describe().round(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare log vs simple returns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ticker = 'AAPL'\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(simple_returns[ticker] * 100, log_returns[ticker] * 100, \n",
    "                alpha=0.5, s=10, color='#2E86AB')\n",
    "axes[0].plot([-5, 5], [-5, 5], 'r--', alpha=0.5, label='y=x')\n",
    "axes[0].set_xlabel('Simple Returns (%)', fontsize=11)\n",
    "axes[0].set_ylabel('Log Returns (%)', fontsize=11)\n",
    "axes[0].set_title('Log vs Simple Returns', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Difference over time\n",
    "diff = (simple_returns[ticker] - log_returns[ticker]) * 100\n",
    "axes[1].plot(diff.index, diff, linewidth=1, alpha=0.7, color='#A23B72')\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_ylabel('Difference (%)', fontsize=11)\n",
    "axes[1].set_title('Difference (Simple - Log)', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä For small returns, log ‚âà simple returns\")\n",
    "print(f\"   Mean difference: {diff.mean():.6f}%\")\n",
    "print(f\"   Max difference:  {diff.abs().max():.6f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6deb006",
   "metadata": {},
   "source": [
    "## 5. Returns Analysis\n",
    "\n",
    "Perform comprehensive statistical analysis on returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ReturnsCalculator for detailed analysis\n",
    "calc = ReturnsCalculator()\n",
    "stats = calc.get_statistics(log_returns)\n",
    "\n",
    "print(\"üìä Detailed Return Statistics:\\n\")\n",
    "print(stats.round(6))\n",
    "\n",
    "# Calculate annualized metrics\n",
    "print(\"\\nüìä Annualized Metrics:\")\n",
    "for ticker in log_returns.columns:\n",
    "    mean_daily = log_returns[ticker].mean()\n",
    "    std_daily = log_returns[ticker].std()\n",
    "    \n",
    "    mean_annual = mean_daily * 252\n",
    "    std_annual = std_daily * np.sqrt(252)\n",
    "    sharpe = mean_annual / std_annual if std_annual > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"   Mean Return: {mean_annual*100:7.2f}%\")\n",
    "    print(f\"   Volatility:  {std_annual*100:7.2f}%\")\n",
    "    print(f\"   Sharpe:      {sharpe:7.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution analysis\n",
    "fig, axes = plt.subplots(2, len(tickers), figsize=(14, 8))\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    returns_pct = log_returns[ticker] * 100\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0, idx].hist(returns_pct, bins=50, alpha=0.7, color=colors[idx], edgecolor='black')\n",
    "    axes[0, idx].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[0, idx].set_title(f'{ticker} Returns Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, idx].set_xlabel('Returns (%)', fontsize=10)\n",
    "    axes[0, idx].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[0, idx].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Q-Q plot\n",
    "    from scipy import stats as sp_stats\n",
    "    sp_stats.probplot(returns_pct, dist=\"norm\", plot=axes[1, idx])\n",
    "    axes[1, idx].set_title(f'{ticker} Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Normality Assessment:\")\n",
    "for ticker in tickers:\n",
    "    skew = log_returns[ticker].skew()\n",
    "    kurt = log_returns[ticker].kurtosis()\n",
    "    print(f\"\\n{ticker}:\")\n",
    "    print(f\"   Skewness: {skew:7.3f} ({'left-skewed' if skew < 0 else 'right-skewed'})\")\n",
    "    print(f\"   Kurtosis: {kurt:7.3f} ({'fat tails' if kurt > 0 else 'thin tails'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136986e0",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis\n",
    "\n",
    "Analyze correlations between different assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d78498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = log_returns.corr()\n",
    "\n",
    "print(\"üìä Return Correlation Matrix:\\n\")\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdYlBu_r', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "            fmt='.3f', vmin=-1, vmax=1)\n",
    "plt.title('Return Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cf401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling correlation\n",
    "if len(tickers) >= 2:\n",
    "    ticker1, ticker2 = tickers[0], tickers[1]\n",
    "    \n",
    "    rolling_corr = log_returns[ticker1].rolling(window=60).corr(log_returns[ticker2])\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(rolling_corr.index, rolling_corr, linewidth=2, color='#2E86AB')\n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    plt.fill_between(rolling_corr.index, 0, rolling_corr, alpha=0.3, color='#2E86AB')\n",
    "    plt.title(f'60-Day Rolling Correlation: {ticker1} vs {ticker2}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=11)\n",
    "    plt.ylabel('Correlation', fontsize=11)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Correlation Statistics ({ticker1} vs {ticker2}):\")\n",
    "    print(f\"   Mean: {rolling_corr.mean():.3f}\")\n",
    "    print(f\"   Std:  {rolling_corr.std():.3f}\")\n",
    "    print(f\"   Min:  {rolling_corr.min():.3f}\")\n",
    "    print(f\"   Max:  {rolling_corr.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a28ca4",
   "metadata": {},
   "source": [
    "## 7. Outlier Detection\n",
    "\n",
    "Identify and analyze outliers in the returns data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using z-score method\n",
    "from scipy import stats\n",
    "\n",
    "print(\"üîç Detecting outliers (|z-score| > 3)...\\n\")\n",
    "\n",
    "for ticker in tickers:\n",
    "    returns_series = log_returns[ticker].dropna()\n",
    "    z_scores = np.abs(stats.zscore(returns_series))\n",
    "    outliers = returns_series[z_scores > 3]\n",
    "    \n",
    "    print(f\"{ticker}:\")\n",
    "    print(f\"   Total outliers: {len(outliers)}\")\n",
    "    print(f\"   Percentage:     {len(outliers)/len(returns_series)*100:.2f}%\")\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\"   Largest positive: {outliers.max()*100:7.2f}% on {outliers.idxmax().date()}\")\n",
    "        print(f\"   Largest negative: {outliers.min()*100:7.2f}% on {outliers.idxmin().date()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab9ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(len(tickers), 1, figsize=(14, 4*len(tickers)))\n",
    "\n",
    "for idx, ticker in enumerate(tickers):\n",
    "    ax = axes[idx] if len(tickers) > 1 else axes\n",
    "    \n",
    "    returns_series = log_returns[ticker] * 100\n",
    "    z_scores = np.abs(stats.zscore(log_returns[ticker].dropna()))\n",
    "    \n",
    "    # Plot all returns\n",
    "    ax.scatter(returns_series.index, returns_series, alpha=0.4, s=10, \n",
    "               color=colors[idx], label='Normal')\n",
    "    \n",
    "    # Highlight outliers\n",
    "    outlier_mask = z_scores > 3\n",
    "    outlier_dates = returns_series.index[outlier_mask]\n",
    "    outlier_values = returns_series[outlier_mask]\n",
    "    ax.scatter(outlier_dates, outlier_values, color='red', s=50, \n",
    "               marker='x', label='Outliers', zorder=5)\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "    ax.set_title(f'{ticker} Returns with Outliers', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=11)\n",
    "    ax.set_ylabel('Returns (%)', fontsize=11)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e89b3",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "Let's summarize our data analysis findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"{'DATA ANALYSIS SUMMARY':^70}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Dataset Info:\")\n",
    "print(f\"   Tickers: {', '.join(tickers)}\")\n",
    "print(f\"   Period:  {clean_prices.index[0].date()} to {clean_prices.index[-1].date()}\")\n",
    "print(f\"   Days:    {len(clean_prices)}\")\n",
    "\n",
    "print(f\"\\nüìä Data Quality:\")\n",
    "print(f\"   Missing values: {clean_prices.isna().sum().sum()}\")\n",
    "print(f\"   Zero values:    {(clean_prices == 0).sum().sum()}\")\n",
    "print(f\"   Date gaps (>7d): {len(large_gaps) if 'large_gaps' in locals() else 0}\")\n",
    "\n",
    "print(f\"\\nüìä Returns Statistics (Annualized):\")\n",
    "for ticker in tickers:\n",
    "    mean_ret = log_returns[ticker].mean() * 252\n",
    "    std_ret = log_returns[ticker].std() * np.sqrt(252)\n",
    "    sharpe = mean_ret / std_ret\n",
    "    \n",
    "    print(f\"\\n   {ticker}:\")\n",
    "    print(f\"      Return:  {mean_ret*100:6.2f}%\")\n",
    "    print(f\"      Vol:     {std_ret*100:6.2f}%\")\n",
    "    print(f\"      Sharpe:  {sharpe:6.2f}\")\n",
    "\n",
    "print(f\"\\nüìä Distribution Properties:\")\n",
    "for ticker in tickers:\n",
    "    skew = log_returns[ticker].skew()\n",
    "    kurt = log_returns[ticker].kurtosis()\n",
    "    print(f\"\\n   {ticker}:\")\n",
    "    print(f\"      Skewness: {skew:6.3f}\")\n",
    "    print(f\"      Kurtosis: {kurt:6.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Data Analysis Complete!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab3f75",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **03_volatility_models.ipynb**: Deep dive into volatility modeling\n",
    "- **04_regime_analysis.ipynb**: Advanced regime classification\n",
    "- **05_strategy_integration.ipynb**: Integrate with trading strategies\n",
    "\n",
    "---\n",
    "\n",
    "**Continue exploring! üìäüîç**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
